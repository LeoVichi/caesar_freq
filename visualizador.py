import argparse
import pandas as pd
import matplotlib.pyplot as plt
from wordcloud import WordCloud
from collections import Counter

# ğŸ›ï¸ Argumentos CLI
parser = argparse.ArgumentParser(
    description="VisualizaÃ§Ã£o de frequÃªncia de palavras por categoria gramatical"
)
parser.add_argument(
    "--csv", type=str, required=True,
    help="Arquivo CSV anotado com Token, Lema, POS ou jÃ¡ agregados com coluna 'FrequÃªncia'"
)
parser.add_argument(
    "--limite", type=int, default=30,
    help="NÃºmero de itens a exibir nos grÃ¡ficos"
)
parser.add_argument(
    "--tipo", choices=["substantivo", "verbo", "adjetivo"], required=True,
    help="Tipo morfossintÃ¡tico: substantivo, verbo, adjetivo"
)
parser.add_argument(
    "--grafico", choices=["bar", "cloud"], required=True,
    help="Tipo de grÃ¡fico: bar (barras) ou cloud (nuvem)"
)
parser.add_argument(
    "--formato", choices=["png", "svg", "pdf"], default="png",
    help="Formato de saÃ­da do grÃ¡fico"
)
args = parser.parse_args()

# ğŸ“¥ Carregamento do CSV
data_file = args.csv
try:
    df = pd.read_csv(data_file)
except FileNotFoundError:
    print(f"âŒ Arquivo nÃ£o encontrado: {data_file}")
    exit(1)

# ğŸ¯ Mapeamento do tipo morfossintÃ¡tico
mapa_tipo = {
    "substantivo": "NOUN",
    "verbo":      "VERB",
    "adjetivo":   "ADJ",
}
tipo_pos = mapa_tipo[args.tipo]

# ğŸ” Filtragem de POS e preparaÃ§Ã£o de FrequÃªncias
mask = df['POS'] == tipo_pos
df_filtrado = df.loc[mask].copy()
# Normaliza lemmas
df_filtrado['Lema'] = df_filtrado['Lema'].astype(str).str.lower().str.strip()
# Remove registros vazios
df_filtrado = df_filtrado[df_filtrado['Lema'].ne('') & df_filtrado['Lema'].notna()]

# ğŸ“Š Computa sÃ©rie de frequÃªncias
if 'FrequÃªncia' in df_filtrado.columns:
    # CSV jÃ¡ possui coluna de frequÃªncia agregada
    freq_series = df_filtrado.set_index('Lema')['FrequÃªncia'].astype(int)
    freq_series = freq_series.groupby(level=0).sum().sort_values(ascending=False)
else:
    # conta ocorrÃªncias de lemma
    freq_series = df_filtrado['Lema'].value_counts()

# Top N
top = freq_series.head(args.limite)
lemas = top.index.tolist()
frequencias = top.values.tolist()

# ExtensÃ£o de saÃ­da
ext = args.formato

# ğŸ“ˆ GrÃ¡fico de barras
if args.grafico == 'bar':
    plt.figure(figsize=(12, 8))
    bars = plt.barh(lemas[::-1], frequencias[::-1], color='#4c72b0')
    plt.xlabel('FrequÃªncia')
    plt.title(f"Top {args.limite} {args.tipo.upper()}S mais frequentes")
    maxf = max(frequencias) if frequencias else 1
    plt.xlim(0, maxf * 1.1)
    # rÃ³tulo ao final de cada barra
    for bar, freq in zip(bars, frequencias[::-1]):
        x = bar.get_width()
        y = bar.get_y() + bar.get_height() / 2
        plt.text(x + maxf * 0.01, y, str(freq), va='center')
    plt.tight_layout()
    out_file = f"top_{args.tipo}_{args.limite}.{ext}"
    plt.savefig(out_file)
    plt.show()
    print(f"ğŸ“¦ Exportado: {out_file}")

# â˜ï¸ Nuvem de palavras
elif args.grafico == 'cloud':
    # usa apenas o top N definido em top
    top_dict = dict(zip(lemas, frequencias))
    wc = WordCloud(width=1000, height=600, background_color='white', colormap='viridis')
    wc.generate_from_frequencies(top_dict)
    plt.figure(figsize=(10, 6))
    plt.imshow(wc, interpolation='bilinear')
    plt.axis('off')
    plt.title(f"Nuvem de Palavras: {args.tipo.upper()}S")
    plt.tight_layout()
    out_file = f"nuvem_{args.tipo}.{ext}"
    plt.savefig(out_file)
    plt.show()
    print(f"ğŸ“¦ Exportado: {out_file}")

